
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.1.4">
    
    
      
        <title>Bagging - Data Science Foundations</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.bb3983ee.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.e6a45f82.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../extra.css">
    
      <link rel="stylesheet" href="../styles.css">
    
    <script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  


  <script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-114664473-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){var e;this.value&&(e=document.location.pathname,ga("send","pageview",e+"?q="+this.value))}),"undefined"!=typeof location$&&location$.subscribe(function(e){ga("send","pageview",e.pathname)})})</script>
  <script async src="https://www.google-analytics.com/analytics.js"></script>


    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent="">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#data-science-foundations-session-6-bagging-decision-trees-and-random-forests" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Data Science Foundations" class="md-header__button md-logo" aria-label="Data Science Foundations" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Data Science Foundations
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Bagging
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Data Science Foundations" class="md-nav__button md-logo" aria-label="Data Science Foundations" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    Data Science Foundations
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        About
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../introduction/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Sessions
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Sessions" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Sessions
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../S1_Regression_and_Analysis/" class="md-nav__link">
        Regression and Analysis
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../S2_Inferential_Statistics/" class="md-nav__link">
        Inferential Statistics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../S3_Model_Selection_and_Validation/" class="md-nav__link">
        Model Selection and Validation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../S4_Feature_Engineering/" class="md-nav__link">
        Feature Engineering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../S5_Unsupervised_Learning/" class="md-nav__link">
        Unsupervised Learning
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Bagging
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Bagging
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#60-preparing-environment-and-importing-data" class="md-nav__link">
    6.0 Preparing Environment and Importing Data
  </a>
  
    <nav class="md-nav" aria-label="6.0 Preparing Environment and Importing Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#601-import-packages" class="md-nav__link">
    6.0.1 Import Packages
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#602-load-dataset" class="md-nav__link">
    6.0.2 Load Dataset
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#61-decision-trees" class="md-nav__link">
    6.1 Decision Trees
  </a>
  
    <nav class="md-nav" aria-label="6.1 Decision Trees">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#611-creating-a-decision-tree" class="md-nav__link">
    6.1.1 Creating a Decision Tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#612-interpreting-a-decision-tree" class="md-nav__link">
    6.1.2 Interpreting a Decision Tree
  </a>
  
    <nav class="md-nav" aria-label="6.1.2 Interpreting a Decision Tree">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#6121-node-branch-diagram" class="md-nav__link">
    6.1.2.1 Node &amp; Branch Diagram
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6121-decision-boundaries" class="md-nav__link">
    6.1.2.1 Decision Boundaries
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#613-overfitting-a-decision-tree" class="md-nav__link">
    6.1.3 Overfitting a Decision Tree
  </a>
  
    <nav class="md-nav" aria-label="6.1.3 Overfitting a Decision Tree">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#exercise-1-minimize-overfitting" class="md-nav__link">
    üèãÔ∏è Exercise 1: Minimize Overfitting
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#62-random-forests-and-bagging" class="md-nav__link">
    6.2 Random Forests and Bagging
  </a>
  
    <nav class="md-nav" aria-label="6.2 Random Forests and Bagging">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#621-what-is-bagging" class="md-nav__link">
    6.2.1 What is Bagging?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#622-random-forests-for-classification" class="md-nav__link">
    6.2.2 Random Forests for Classification
  </a>
  
    <nav class="md-nav" aria-label="6.2.2 Random Forests for Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#6221-interpreting-a-random-forest" class="md-nav__link">
    6.2.2.1 Interpreting a Random Forest
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#question-1-feature-importance-and-cardinality" class="md-nav__link">
    üôã‚Äç‚ôÄÔ∏è Question 1: Feature Importance and Cardinality
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#question-2-compare-to-moods-median" class="md-nav__link">
    üôã‚Äç Question 2: Compare to Moods Median
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#623-random-forests-for-regression" class="md-nav__link">
    6.2.3 Random Forests for Regression
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exercise-2-practice-with-random-forests" class="md-nav__link">
    üèãÔ∏è Exercise 2: Practice with Random Forests
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../S7_Boosting/" class="md-nav__link">
        Boosting
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Labs
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Labs" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Labs
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../labs/L1_Descriptive_Statistics_Data_Hunt/" class="md-nav__link">
        Descriptive Statistics Data Hunt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../labs/L2_Inferential_Statistics_Data_Hunt/" class="md-nav__link">
        Inferential Statistics Data Hunt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../labs/L3_Feature_Engineering/" class="md-nav__link">
        Practice with Feature Engineering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../labs/L4_Supervised_Learners/" class="md-nav__link">
        Practice with Supervised Learners
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../labs/L5_Writing_Unit_Tests/" class="md-nav__link">
        Practice with Writing Unit Tests
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          Project
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Project" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Project
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../project/P1_Statistical_Analysis_of_TicTacToe/" class="md-nav__link">
        Statistical Analysis of TicTacToe
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../project/P2_Heuristical_TicTacToe_Agents/" class="md-nav__link">
        Heuristical TicTacToe Agents
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../project/P3_1_Step_Look_Ahead_Agents/" class="md-nav__link">
        1-Step Look Ahead Agents
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../project/P4_N_Step_Look_Ahead_Agents/" class="md-nav__link">
        N-Step Look Ahead Agents
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6">
          Extras
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Extras" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Extras
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../extras/X1_Bayesian_Probability/" class="md-nav__link">
        Probability
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../extras/X2_Airbnb/" class="md-nav__link">
        Airbnb
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../extras/X3_AB_Testing/" class="md-nav__link">
        AB Tests
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../extras/X4_Spotify_Appendix/" class="md-nav__link">
        Spotify
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#60-preparing-environment-and-importing-data" class="md-nav__link">
    6.0 Preparing Environment and Importing Data
  </a>
  
    <nav class="md-nav" aria-label="6.0 Preparing Environment and Importing Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#601-import-packages" class="md-nav__link">
    6.0.1 Import Packages
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#602-load-dataset" class="md-nav__link">
    6.0.2 Load Dataset
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#61-decision-trees" class="md-nav__link">
    6.1 Decision Trees
  </a>
  
    <nav class="md-nav" aria-label="6.1 Decision Trees">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#611-creating-a-decision-tree" class="md-nav__link">
    6.1.1 Creating a Decision Tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#612-interpreting-a-decision-tree" class="md-nav__link">
    6.1.2 Interpreting a Decision Tree
  </a>
  
    <nav class="md-nav" aria-label="6.1.2 Interpreting a Decision Tree">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#6121-node-branch-diagram" class="md-nav__link">
    6.1.2.1 Node &amp; Branch Diagram
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6121-decision-boundaries" class="md-nav__link">
    6.1.2.1 Decision Boundaries
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#613-overfitting-a-decision-tree" class="md-nav__link">
    6.1.3 Overfitting a Decision Tree
  </a>
  
    <nav class="md-nav" aria-label="6.1.3 Overfitting a Decision Tree">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#exercise-1-minimize-overfitting" class="md-nav__link">
    üèãÔ∏è Exercise 1: Minimize Overfitting
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#62-random-forests-and-bagging" class="md-nav__link">
    6.2 Random Forests and Bagging
  </a>
  
    <nav class="md-nav" aria-label="6.2 Random Forests and Bagging">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#621-what-is-bagging" class="md-nav__link">
    6.2.1 What is Bagging?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#622-random-forests-for-classification" class="md-nav__link">
    6.2.2 Random Forests for Classification
  </a>
  
    <nav class="md-nav" aria-label="6.2.2 Random Forests for Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#6221-interpreting-a-random-forest" class="md-nav__link">
    6.2.2.1 Interpreting a Random Forest
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#question-1-feature-importance-and-cardinality" class="md-nav__link">
    üôã‚Äç‚ôÄÔ∏è Question 1: Feature Importance and Cardinality
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#question-2-compare-to-moods-median" class="md-nav__link">
    üôã‚Äç Question 2: Compare to Moods Median
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#623-random-forests-for-regression" class="md-nav__link">
    6.2.3 Random Forests for Regression
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exercise-2-practice-with-random-forests" class="md-nav__link">
    üèãÔ∏è Exercise 2: Practice with Random Forests
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                

<p><a href="https://colab.research.google.com/github/wesleybeckner/data_science_foundations/blob/main/notebooks/S6_Bagging.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<h1 id="data-science-foundations-session-6-bagging-decision-trees-and-random-forests">Data Science Foundations <br> Session 6: Bagging <br> <em>Decision Trees and Random Forests</em><a class="headerlink" href="#data-science-foundations-session-6-bagging-decision-trees-and-random-forests" title="Permanent link">&para;</a></h1>
<p><strong>Instructor</strong>: Wesley Beckner</p>
<p><strong>Contact</strong>: <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#119;&#101;&#115;&#108;&#101;&#121;&#98;&#101;&#99;&#107;&#110;&#101;&#114;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;">&#119;&#101;&#115;&#108;&#101;&#121;&#98;&#101;&#99;&#107;&#110;&#101;&#114;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;</a></p>
<hr />
<p><br></p>
<p>In this session, we're going back to the topic of supervised learning models. These models however, belong to a special class of methods called bagging, or bootstrap aggregation. </p>
<p>Bagging is an ensemble learning method. In this method, many weak classifiers cast their votes in a general election for the final prediction. </p>
<p>The weak learners that random forests are made of, are called decision trees. </p>
<p align="center">
<img src="https://media.giphy.com/media/uX5BYSQALx12o/giphy.gif" width=400px></img>
</p>

<p><br></p>
<hr />
<p><a name='top'></a></p>
<p><a name='x.0'></a></p>
<h2 id="60-preparing-environment-and-importing-data">6.0 Preparing Environment and Importing Data<a class="headerlink" href="#60-preparing-environment-and-importing-data" title="Permanent link">&para;</a></h2>
<p><a href="#top">back to top</a></p>
<p><a name='x.0.1'></a></p>
<h3 id="601-import-packages">6.0.1 Import Packages<a class="headerlink" href="#601-import-packages" title="Permanent link">&para;</a></h3>
<p><a href="#top">back to top</a></p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="nn">px</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">statsmodels.stats.outliers_influence</span> <span class="kn">import</span> <span class="n">variance_inflation_factor</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span><span class="p">;</span> <span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="kn">import</span> <span class="nn">graphviz</span> 
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">widgets</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
</code></pre></div>

<p><a name='x.0.2'></a></p>
<h3 id="602-load-dataset">6.0.2 Load Dataset<a class="headerlink" href="#602-load-dataset" title="Permanent link">&para;</a></h3>
<p><a href="#top">back to top</a></p>
<div class="codehilite"><pre><span></span><code><span class="n">margin</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/wesleybeckner/&#39;</span>\
                 <span class="s1">&#39;ds_for_engineers/main/data/truffle_margin/truffle_margin_customer.csv&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">margin</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">margin</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>(1668, 9)
</code></pre></div>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Base Cake</th>
      <th>Truffle Type</th>
      <th>Primary Flavor</th>
      <th>Secondary Flavor</th>
      <th>Color Group</th>
      <th>Customer</th>
      <th>Date</th>
      <th>KG</th>
      <th>EBITDA/KG</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Butter</td>
      <td>Candy Outer</td>
      <td>Butter Pecan</td>
      <td>Toffee</td>
      <td>Taupe</td>
      <td>Slugworth</td>
      <td>1/2020</td>
      <td>53770.342593</td>
      <td>0.500424</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Butter</td>
      <td>Candy Outer</td>
      <td>Ginger Lime</td>
      <td>Banana</td>
      <td>Amethyst</td>
      <td>Slugworth</td>
      <td>1/2020</td>
      <td>466477.578125</td>
      <td>0.220395</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Butter</td>
      <td>Candy Outer</td>
      <td>Ginger Lime</td>
      <td>Banana</td>
      <td>Burgundy</td>
      <td>Perk-a-Cola</td>
      <td>1/2020</td>
      <td>80801.728070</td>
      <td>0.171014</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Butter</td>
      <td>Candy Outer</td>
      <td>Ginger Lime</td>
      <td>Banana</td>
      <td>White</td>
      <td>Fickelgruber</td>
      <td>1/2020</td>
      <td>18046.111111</td>
      <td>0.233025</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Butter</td>
      <td>Candy Outer</td>
      <td>Ginger Lime</td>
      <td>Rum</td>
      <td>Amethyst</td>
      <td>Fickelgruber</td>
      <td>1/2020</td>
      <td>19147.454268</td>
      <td>0.480689</td>
    </tr>
  </tbody>
</table>
</div>

<p>We're going to recreate the same operations we employed in Session 4, Feature Engineering:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># identify categorical columns</span>
<span class="n">cat_cols</span> <span class="o">=</span> <span class="n">margin</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span><span class="mi">7</span><span class="p">]</span>

<span class="c1"># create the encoder object</span>
<span class="n">enc</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>

<span class="c1"># grab the columns we want to convert from strings</span>
<span class="n">X_cat</span> <span class="o">=</span> <span class="n">margin</span><span class="p">[</span><span class="n">cat_cols</span><span class="p">]</span>

<span class="c1"># fit our encoder to this data</span>
<span class="n">enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_cat</span><span class="p">)</span>
<span class="n">onehotlabels</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_cat</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">X_num</span> <span class="o">=</span> <span class="n">margin</span><span class="p">[[</span><span class="s1">&#39;KG&#39;</span><span class="p">]]</span>
<span class="n">X_truf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">onehotlabels</span><span class="p">,</span> <span class="n">X_num</span><span class="o">.</span><span class="n">values</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># grab our y data</span>
<span class="n">y_truf</span> <span class="o">=</span> <span class="n">margin</span><span class="p">[</span><span class="s1">&#39;EBITDA/KG&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</code></pre></div>

<p>Lastly, to create a classification task, we're going to identify high, med, and low value products:</p>
<div class="codehilite"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;bad less than: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">margin</span><span class="p">[</span><span class="n">margin</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">.25</span><span class="p">)),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;low less than: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">margin</span><span class="p">[</span><span class="n">margin</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">.5</span><span class="p">)),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;med less than: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">margin</span><span class="p">[</span><span class="n">margin</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">.75</span><span class="p">)),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">margin</span><span class="p">[</span><span class="n">margin</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">showfliers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>bad less than: 0.12

low less than: 0.22

med less than: 0.35






&lt;AxesSubplot:&gt;
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_10_2.png" /></p>
<div class="codehilite"><pre><span></span><code><span class="n">margin</span><span class="p">[</span><span class="s1">&#39;profitability&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">margin</span><span class="p">[</span><span class="n">margin</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;bad&#39;</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">margin</span><span class="p">[</span><span class="n">margin</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">.25</span><span class="p">)</span> <span class="k">else</span>
              <span class="s1">&#39;low&#39;</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">margin</span><span class="p">[</span><span class="n">margin</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">.50</span><span class="p">)</span> <span class="k">else</span>
              <span class="s1">&#39;med&#39;</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">margin</span><span class="p">[</span><span class="n">margin</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">.75</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;high&#39;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">margin</span><span class="p">[</span><span class="s1">&#39;profitability&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">()</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&lt;AxesSubplot:&gt;
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_12_1.png" /></p>
<div class="codehilite"><pre><span></span><code><span class="n">class_profit</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;bad&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;low&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;med&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;high&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="n">y_truf_class</span> <span class="o">=</span> <span class="n">margin</span><span class="p">[</span><span class="s1">&#39;profitability&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">class_profit</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">margin</span><span class="p">[</span><span class="s1">&#39;profitability_encoding&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_truf_class</span>
<span class="n">margin</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Base Cake</th>
      <th>Truffle Type</th>
      <th>Primary Flavor</th>
      <th>Secondary Flavor</th>
      <th>Color Group</th>
      <th>Customer</th>
      <th>Date</th>
      <th>KG</th>
      <th>EBITDA/KG</th>
      <th>profitability</th>
      <th>profitability_encoding</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Butter</td>
      <td>Candy Outer</td>
      <td>Butter Pecan</td>
      <td>Toffee</td>
      <td>Taupe</td>
      <td>Slugworth</td>
      <td>1/2020</td>
      <td>53770.342593</td>
      <td>0.500424</td>
      <td>high</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Butter</td>
      <td>Candy Outer</td>
      <td>Ginger Lime</td>
      <td>Banana</td>
      <td>Amethyst</td>
      <td>Slugworth</td>
      <td>1/2020</td>
      <td>466477.578125</td>
      <td>0.220395</td>
      <td>med</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Butter</td>
      <td>Candy Outer</td>
      <td>Ginger Lime</td>
      <td>Banana</td>
      <td>Burgundy</td>
      <td>Perk-a-Cola</td>
      <td>1/2020</td>
      <td>80801.728070</td>
      <td>0.171014</td>
      <td>low</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Butter</td>
      <td>Candy Outer</td>
      <td>Ginger Lime</td>
      <td>Banana</td>
      <td>White</td>
      <td>Fickelgruber</td>
      <td>1/2020</td>
      <td>18046.111111</td>
      <td>0.233025</td>
      <td>med</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Butter</td>
      <td>Candy Outer</td>
      <td>Ginger Lime</td>
      <td>Rum</td>
      <td>Amethyst</td>
      <td>Fickelgruber</td>
      <td>1/2020</td>
      <td>19147.454268</td>
      <td>0.480689</td>
      <td>high</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>

<p><a name='x.1'></a></p>
<h2 id="61-decision-trees">6.1 Decision Trees<a class="headerlink" href="#61-decision-trees" title="Permanent link">&para;</a></h2>
<p><a href="#top">back to top</a></p>
<p>In essence, a decision tree is a series of binary questions. </p>
<p><img src="https://miro.medium.com/max/499/0*KQUBhmPmWeP8mHQz.jpeg" width=400px></img></p>
<p>Let's begin this discussion by talking about how we make decision trees in sklearn.</p>
<p><a name='x.1.1'></a></p>
<h3 id="611-creating-a-decision-tree">6.1.1 Creating a Decision Tree<a class="headerlink" href="#611-creating-a-decision-tree" title="Permanent link">&para;</a></h3>
<p><a href="#top">back to top</a></p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div>

<p>After fitting the model we can use the predict method to show the output for a sample</p>
<div class="codehilite"><pre><span></span><code><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]])</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>array([1])
</code></pre></div>

<p>Similar to what we saw with GMMs, we also have access to the probabilities of the outcomes:</p>
<div class="codehilite"><pre><span></span><code><span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">([[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]])</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>array([[0., 1.]])
</code></pre></div>

<p>Let's now go on to using visual strategies to interpreting trees.</p>
<p><a name='x.1.2'></a></p>
<h3 id="612-interpreting-a-decision-tree">6.1.2 Interpreting a Decision Tree<a class="headerlink" href="#612-interpreting-a-decision-tree" title="Permanent link">&para;</a></h3>
<p><a href="#top">back to top</a></p>
<p>Throughout today, we will discuss many ways to view both a single tree and a random forest of trees.</p>
<p><a name='x.1.2.1'></a></p>
<h4 id="6121-node-branch-diagram">6.1.2.1 Node &amp; Branch Diagram<a class="headerlink" href="#6121-node-branch-diagram" title="Permanent link">&para;</a></h4>
<p><a href="#top">back to top</a></p>
<p>We can visualize the decision tree:</p>
<div class="codehilite"><pre><span></span><code><span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>[Text(0.5, 0.75, &#39;X[1] &lt;= 0.5\ngini = 0.5\nsamples = 2\nvalue = [1, 1]&#39;),
 Text(0.25, 0.25, &#39;gini = 0.0\nsamples = 1\nvalue = [1, 0]&#39;),
 Text(0.75, 0.25, &#39;gini = 0.0\nsamples = 1\nvalue = [0, 1]&#39;)]
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_24_1.png" /></p>
<p>or, more prettily:</p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span> <span class="nn">graphviz</span> 
<span class="n">dot_data</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> 
<span class="n">graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot_data</span><span class="p">)</span> 
<span class="n">graph</span>
</code></pre></div>

<p><img alt="svg" src="../S6_Bagging_files/S6_Bagging_26_0.svg" /></p>
<p>The gini label, also known as <strong>Gini impurity</strong>, is a measure of how often a sample passing through the node would be incorrectly labeled if it was randomly assigned a label based on the proportion of all labels passing through the node. So it is a measure of the progress of our tree.</p>
<p>Let's take a more complex example</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span> <span class="k">as</span> <span class="n">gen</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div>

<p>Let's inspect our generated data:</p>
<div class="codehilite"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">y</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span> <span class="c1"># a binary classification</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>(100, 20)
(100,)





array([0, 0, 1, 1, 0])
</code></pre></div>

<p>And now let's train our tree:</p>
<div class="codehilite"><pre><span></span><code><span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div>

<p>How do we interpret this graph?</p>
<div class="codehilite"><pre><span></span><code><span class="n">dot_data</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> 
<span class="n">graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot_data</span><span class="p">)</span> 
<span class="n">graph</span>
</code></pre></div>

<p><img alt="svg" src="../S6_Bagging_files/S6_Bagging_35_0.svg" /></p>
<blockquote>
<p>Can we confirm the observations in the tree by manually inspecting X and y?</p>
</blockquote>
<div class="codehilite"><pre><span></span><code><span class="n">y</span><span class="p">[</span><span class="n">X</span><span class="p">[:,</span><span class="mi">10</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">.203</span><span class="p">]</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0])
</code></pre></div>

<p>We can confirm the gini score of the top left node by hand...</p>
<div class="codehilite"><pre><span></span><code><span class="n">scr</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
  <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="p">(</span> <span class="mi">3</span><span class="o">/</span><span class="mi">52</span> <span class="p">)</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">52</span><span class="p">)]</span>
  <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="p">(</span> <span class="mi">3</span><span class="o">/</span><span class="mi">52</span> <span class="p">)</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">52</span><span class="p">)]</span>
  <span class="n">scr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="n">y_true</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scr</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>0.1091346153846154
</code></pre></div>

<p>Let's take a look at this with our truffle dataset</p>
<blockquote>
<p>Vary the parameter <code>max_depth</code> what do you notice? Does the term <em>greedy</em> mean anything to you? Do nodes higher in the tree change based on decisions lower in the tree?</p>
</blockquote>
<div class="codehilite"><pre><span></span><code><span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_truf</span><span class="p">,</span> <span class="n">y_truf_class</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>DecisionTreeClassifier(max_depth=1)
</code></pre></div>

<p>And now lets look at the graph:</p>
<div class="codehilite"><pre><span></span><code><span class="n">dot_data</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> 
<span class="n">graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot_data</span><span class="p">)</span> 
<span class="n">graph</span>
</code></pre></div>

<p><img alt="svg" src="../S6_Bagging_files/S6_Bagging_43_0.svg" /></p>
<p>What is <code>X[4]</code>???</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># It&#39;s those tasty sponge cake truffles!</span>
<span class="n">enc</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()[</span><span class="mi">4</span><span class="p">]</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&#39;Base Cake_Sponge&#39;
</code></pre></div>

<p>This is one great aspect of decision trees, their <em>interpretability</em>.</p>
<p>We will perform this analysis again, for now, let's proceed with simpler datasets while exploring the features of decision trees.</p>
<p><a name='x.1.2.2'></a></p>
<h4 id="6121-decision-boundaries">6.1.2.1 Decision Boundaries<a class="headerlink" href="#6121-decision-boundaries" title="Permanent link">&para;</a></h4>
<p><a href="#top">back to top</a></p>
<p>Let's make some random blobs</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span> <span class="k">as</span> <span class="n">gen</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&lt;matplotlib.collections.PathCollection at 0x7f850da667c0&gt;
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_49_1.png" /></p>
<p>Let's call up our Classifier again, this time setting the <code>max_depth</code> to two</p>
<div class="codehilite"><pre><span></span><code><span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># Parameters</span>
<span class="n">plot_step</span> <span class="o">=</span> <span class="mf">0.02</span>

<span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">plot_step</span><span class="p">),</span>
                      <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">plot_step</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">h_pad</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">w_pad</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span>

<span class="n">Z</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">cs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&lt;matplotlib.collections.PathCollection at 0x7f850cc0f9d0&gt;
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_52_1.png" /></p>
<div class="codehilite"><pre><span></span><code><span class="n">dot_data</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> 
<span class="n">graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot_data</span><span class="p">)</span> 
<span class="n">graph</span>
</code></pre></div>

<p><img alt="svg" src="../S6_Bagging_files/S6_Bagging_53_0.svg" /></p>
<p>We can see from the output of this graph, that the tree attempts to create the class boundaries as far from the cluster centers as possible. What happens when these clusters overlap?</p>
<div class="codehilite"><pre><span></span><code><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&lt;matplotlib.collections.PathCollection at 0x7f850cb877f0&gt;
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_55_1.png" /></p>
<p>Let's go ahead and write our plot into a function</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">plot_tree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">clf</span><span class="p">):</span>
  <span class="n">plot_step</span> <span class="o">=</span> <span class="mf">0.02</span>
  <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
  <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
  <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">plot_step</span><span class="p">),</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">plot_step</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">h_pad</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">w_pad</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span>

  <span class="n">Z</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
  <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">cs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">plt</span>
</code></pre></div>

<p>We see that the boundaries mislabel some points</p>
<div class="codehilite"><pre><span></span><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plot_tree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">clf</span><span class="p">)</span>
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_59_0.png" /></p>
<p><a name='x.1.3'></a></p>
<h3 id="613-overfitting-a-decision-tree">6.1.3 Overfitting a Decision Tree<a class="headerlink" href="#613-overfitting-a-decision-tree" title="Permanent link">&para;</a></h3>
<p><a href="#top">back to top</a></p>
<p>Let's increase the max_depth</p>
<div class="codehilite"><pre><span></span><code><span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">clf</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&lt;module &#39;matplotlib.pyplot&#39; from &#39;/home/wbeckner/anaconda3/envs/py39/lib/python3.9/site-packages/matplotlib/pyplot.py&#39;&gt;
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_61_1.png" /></p>
<p>What we notice is that while the model accurately predicts the training data, we see some spurious labels, noteably the trailing purple bar that extends into the otherwise green region of the data. </p>
<p>This is a well known fact about decision trees, that they tend to overfit their training data. In fact, this is a major motivation for why decision trees, a weak classifier, are conveniently packaged into ensembles.</p>
<p>We combine the idea of bootstrapping, with decision trees, to come up with an overall better classifier.</p>
<h4 id="exercise-1-minimize-overfitting">üèãÔ∏è Exercise 1: Minimize Overfitting<a class="headerlink" href="#exercise-1-minimize-overfitting" title="Permanent link">&para;</a></h4>
<p>Repeat 6.1.3 with different max_depth settings, also read the docstring and play with any other hyperparameters available to you. What settings do you feel minimize overfitting? The documentation for <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html">DecisionTreeClassifier</a> may be helpful</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Code Cell for 1</span>

<span class="c1">################################################################################</span>
<span class="c1">##### CHANGE THE HYPERPARAMETERS IN THE CALL TO DECISIONTREECLASSIFIER #########</span>
<span class="c1">################################################################################</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                                    <span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                    <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                    <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                    <span class="n">min_weight_fraction_leaf</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                    <span class="n">max_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                    <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                    <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                                    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                    <span class="n">ccp_alpha</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">clf</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&lt;module &#39;matplotlib.pyplot&#39; from &#39;/home/wbeckner/anaconda3/envs/py39/lib/python3.9/site-packages/matplotlib/pyplot.py&#39;&gt;
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_64_1.png" /></p>
<p><a name='x.2'></a></p>
<h2 id="62-random-forests-and-bagging">6.2 Random Forests and Bagging<a class="headerlink" href="#62-random-forests-and-bagging" title="Permanent link">&para;</a></h2>
<p><a href="#top">back to top</a></p>
<p><a name='x.2.1'></a></p>
<h3 id="621-what-is-bagging">6.2.1 What is Bagging?<a class="headerlink" href="#621-what-is-bagging" title="Permanent link">&para;</a></h3>
<p><a href="#top">back to top</a></p>
<p><strong><em>Bagging</em></strong>, or Bootstrap AGGregation is the process of creating subsets of your data and training separate models on them, and using the aggregate votes of the models to make a final prediction.</p>
<p><strong><em>Bootstrapping</em></strong> is a topic in and of itself that we will just touch on here. Without going through the statistical rigor of proof, bootstrapping, or sampling from your observations with replacement, simulates having drawn additional data from the true population. We use this method to create many new datasets that are then used to <em>train separate learners</em> in parallel. This overall approach is called <strong><em>Bagging</em></strong>.</p>
<p align=center>
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Ensemble_Bagging.svg/440px-Ensemble_Bagging.svg.png"></img>
</p>

<p>A <strong><em>Random Forest</em></strong> is an instance of bagging where the separate learners are decision trees. </p>
<p><a name='x.2.2'></a></p>
<h3 id="622-random-forests-for-classification">6.2.2 Random Forests for Classification<a class="headerlink" href="#622-random-forests-for-classification" title="Permanent link">&para;</a></h3>
<p><a href="#top">back to top</a></p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">bag</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_samples</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
                        <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">bag</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">bag</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&lt;module &#39;matplotlib.pyplot&#39; from &#39;/home/wbeckner/anaconda3/envs/py39/lib/python3.9/site-packages/matplotlib/pyplot.py&#39;&gt;
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_68_1.png" /></p>
<p>In the above, we have bootstrapped by providing each individual tree with 80% of the population data. In practice, Random Forests can achieve even better results by randomizing how the individual classifiers are constructed. In fact there are many unique methods of training individual trees and you can learn more about them <a href="https://scikit-learn.org/stable/modules/ensemble.html#forest">here</a>. This randomness is done automatically in sklearn's <code>RandomForestClassifier</code></p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">plot_tree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">clf</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&lt;module &#39;matplotlib.pyplot&#39; from &#39;/home/wbeckner/anaconda3/envs/py39/lib/python3.9/site-packages/matplotlib/pyplot.py&#39;&gt;
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_71_1.png" /></p>
<p><a name='x.2.2.1'></a></p>
<h4 id="6221-interpreting-a-random-forest">6.2.2.1 Interpreting a Random Forest<a class="headerlink" href="#6221-interpreting-a-random-forest" title="Permanent link">&para;</a></h4>
<p><a href="#top">back to top</a></p>
<p>Let's revisit our truffle dataset again, this time with random forests</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># fit the model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                             <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_truf</span><span class="p">,</span> <span class="n">y_truf_class</span><span class="p">)</span>
</code></pre></div>

<p>We get a fairly high accuracy when our <code>min_samples_leaf</code> is low and an accuracy that leaves room for improvement when <code>min_samples_leaf</code> is high. This indicates to us the model may be prown to overfitting if we are not careful:</p>
<div class="codehilite"><pre><span></span><code><span class="n">accuracy_score</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_truf</span><span class="p">),</span> <span class="n">y_truf_class</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>0.6127098321342925
</code></pre></div>

<p>We can grab the original feature names with <code>get_feature_names_out()</code>:</p>
<div class="codehilite"><pre><span></span><code><span class="n">feats</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
</code></pre></div>

<p>The feature importances are stored in <code>clf.feature_importances_</code>. These are calculated from the <strong><em>Mean Decrease in Impurity</em></strong> or MDI also called the <strong><em>Gini Importance</em></strong>. It is the sum of the number of nodes across all trees that include the feature, weighted by the number of samples passing through the node. </p>
<p>One downside of estimating feature importance in this way is that it doesn't play well with highly cardinal features <em>(features with many unique values such as mailing addresses, are highly cardinal features)</em></p>
<div class="codehilite"><pre><span></span><code><span class="nb">len</span><span class="p">(</span><span class="n">feats</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>118
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># grab feature importances</span>
<span class="n">imp</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">feature_importances_</span>

<span class="c1"># their std</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">([</span><span class="n">tree</span><span class="o">.</span><span class="n">feature_importances_</span> <span class="k">for</span> <span class="n">tree</span> <span class="ow">in</span> <span class="n">clf</span><span class="o">.</span><span class="n">estimators_</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># create new dataframe</span>
<span class="n">feat</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">feats</span><span class="p">,</span> <span class="n">imp</span><span class="p">,</span> <span class="n">std</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
<span class="n">feat</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">,</span> <span class="s1">&#39;importance&#39;</span><span class="p">,</span> <span class="s1">&#39;std&#39;</span><span class="p">]</span>
<span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;importance&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">feat</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">feat</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>importance</th>
      <th>std</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Base Cake_Sponge</td>
      <td>0.109284</td>
      <td>0.095848</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Base Cake_Chiffon</td>
      <td>0.049163</td>
      <td>0.049299</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Base Cake_Pound</td>
      <td>0.041666</td>
      <td>0.03948</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Base Cake_Butter</td>
      <td>0.038501</td>
      <td>0.038294</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Base Cake_Cheese</td>
      <td>0.033326</td>
      <td>0.037235</td>
    </tr>
  </tbody>
</table>
</div>

<p>I'm going to use <code>plotly</code> to create this chart:</p>
<div class="codehilite"><pre><span></span><code><span class="n">px</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">feat</span><span class="p">[:</span><span class="mi">20</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;feature&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;importance&#39;</span><span class="p">,</span> <span class="n">error_y</span><span class="o">=</span><span class="s1">&#39;std&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Feature Importance&#39;</span><span class="p">)</span>
</code></pre></div>

<h4 id="question-1-feature-importance-and-cardinality">üôã‚Äç‚ôÄÔ∏è Question 1: Feature Importance and Cardinality<a class="headerlink" href="#question-1-feature-importance-and-cardinality" title="Permanent link">&para;</a></h4>
<p>How does feature importance change in the above plot when we change the minimum leaf size from 6 to 1?</p>
<h4 id="question-2-compare-to-moods-median">üôã‚Äç Question 2: Compare to Moods Median<a class="headerlink" href="#question-2-compare-to-moods-median" title="Permanent link">&para;</a></h4>
<p>We can then go and look at the different EBITDAs when selecting for each of these features. What do you notice as the primary difference between these results and those from <a href="https://github.com/wesleybeckner/data_science_foundations/blob/fdf84755a7ed6ed54d3f036a7fc2d9dafa79afd9/notebooks/solutions/SOLN_S2_Inferential_Statistics.ipynb">Session 2: Inferential Statistics Exercise 1, Part C</a> when we ran Mood's Median test on this same data?</p>
<div class="codehilite"><pre><span></span><code><span class="n">feat</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</code></pre></div>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>importance</th>
      <th>std</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Base Cake_Sponge</td>
      <td>0.109284</td>
      <td>0.095848</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Base Cake_Chiffon</td>
      <td>0.049163</td>
      <td>0.049299</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Base Cake_Pound</td>
      <td>0.041666</td>
      <td>0.03948</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Base Cake_Butter</td>
      <td>0.038501</td>
      <td>0.038294</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Base Cake_Cheese</td>
      <td>0.033326</td>
      <td>0.037235</td>
    </tr>
  </tbody>
</table>
</div>

<div class="codehilite"><pre><span></span><code><span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">feat</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10</span><span class="p">,</span><span class="mi">0</span><span class="p">]:</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">feature</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">sel</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">feature</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">margin</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">margin</span><span class="p">[</span><span class="n">group</span><span class="p">]</span> <span class="o">==</span> <span class="n">sel</span><span class="p">)][</span><span class="s1">&#39;EBITDA/KG&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
    <span class="n">neg</span> <span class="o">=</span> <span class="n">margin</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="o">~</span><span class="p">(</span><span class="n">margin</span><span class="p">[</span><span class="n">group</span><span class="p">]</span> <span class="o">==</span> <span class="n">sel</span><span class="p">)][</span><span class="s1">&#39;EBITDA/KG&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">group</span> <span class="o">+</span> <span class="s2">&quot;: &quot;</span> <span class="o">+</span> <span class="n">sel</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">with:    </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pos</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">without: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">neg</span><span class="p">))</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>Base Cake: Sponge
    with:    0.70
    without: 0.20
Base Cake: Chiffon
    with:    0.13
    without: 0.24
Base Cake: Pound
    with:    0.24
    without: 0.20
Base Cake: Butter
    with:    0.14
    without: 0.26
Base Cake: Cheese
    with:    0.44
    without: 0.21
Primary Flavor: Doughnut
    with:    0.38
    without: 0.20
Primary Flavor: Butter Toffee
    with:    0.46
    without: 0.21
Color Group: Olive
    with:    0.67
    without: 0.21
Secondary Flavor: Egg Nog
    with:    0.23
    without: 0.21
Truffle Type: Candy Outer
    with:    0.20
    without: 0.22
</code></pre></div>

<p><a name='x.2.3'></a></p>
<h3 id="623-random-forests-for-regression">6.2.3 Random Forests for Regression<a class="headerlink" href="#623-random-forests-for-regression" title="Permanent link">&para;</a></h3>
<p><a href="#top">back to top</a></p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div>

<p>Because our labels on our blob data were numerical, we can apply and view the estimator in the same way:</p>
<div class="codehilite"><pre><span></span><code><span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">clf</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&lt;module &#39;matplotlib.pyplot&#39; from &#39;/home/wbeckner/anaconda3/envs/py39/lib/python3.9/site-packages/matplotlib/pyplot.py&#39;&gt;
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_90_1.png" /></p>
<p>I want to revisit a dataset we brought up in Session 2 on feature engineering:</p>
<div class="codehilite"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">200</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">h</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">s</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">h</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="n">t</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">w</span><span class="o">*</span><span class="n">t</span><span class="p">)</span><span class="o">/</span><span class="mi">3</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">5</span><span class="o">*</span><span class="n">w</span><span class="o">*</span><span class="n">t</span><span class="p">)</span><span class="o">/</span><span class="mi">5</span><span class="p">)</span>

<span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="n">freq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fftfreq</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="n">t</span><span class="p">),</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="n">t</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="n">t</span><span class="o">*</span><span class="mi">5</span><span class="p">)</span><span class="o">/</span><span class="mi">5</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Time Domain&#39;</span><span class="p">)</span>

<span class="c1"># tells us about the amplitude of the component at the</span>
<span class="c1"># corresponding frequency</span>
<span class="n">magnitude</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">real</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">imag</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">freq</span><span class="p">,</span> <span class="n">magnitude</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">.15</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Frequency Domain&#39;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>Text(0.5, 1.0, &#39;Frequency Domain&#39;)
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_92_1.png" /></p>
<p>Let's see if a random forest regression model can capture the wave behavior of the time-series data</p>
<div class="codehilite"><pre><span></span><code><span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">s</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>RandomForestRegressor(n_estimators=10)
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>[&lt;matplotlib.lines.Line2D at 0x7f850c12adc0&gt;]
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_95_1.png" /></p>
<p>Nice! without specifying any perdiodicity, the random forest does a good job of embedding this periodicity in the final output.</p>
<h3 id="exercise-2-practice-with-random-forests">üèãÔ∏è Exercise 2: Practice with Random Forests<a class="headerlink" href="#exercise-2-practice-with-random-forests" title="Permanent link">&para;</a></h3>
<p>With the wine dataset:</p>
<ul>
<li>predict: density</li>
<li>create a learning curve of train/test score vs model complexity for your random forest model(s)</li>
</ul>
<p>I have provided the <em>cleaned</em> dataset as well as starter code for training the model and making parity plots</p>
<p>Do not change the following 3 cells:</p>
<div class="codehilite"><pre><span></span><code><span class="n">wine</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/wesleybeckner/&quot;</span>\
      <span class="s2">&quot;ds_for_engineers/main/data/wine_quality/winequalityN.csv&quot;</span><span class="p">)</span>
<span class="c1"># infer str cols</span>
<span class="n">str_cols</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">wine</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s1">&#39;object&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="c1">#set target col</span>
<span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;density&#39;</span>

<span class="n">enc</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>
<span class="n">imp</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">()</span>

<span class="n">enc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">wine</span><span class="p">[</span><span class="n">str_cols</span><span class="p">])</span>
<span class="n">X_cat</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">wine</span><span class="p">[</span><span class="n">str_cols</span><span class="p">])</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">str_cols</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">imp</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">X_cat</span><span class="p">,</span> <span class="n">X</span><span class="p">])</span>

<span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">enc</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()]</span>
<span class="n">cols</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">wine</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">cols</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
<span class="p">[</span><span class="n">cols</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">str_cols</span><span class="p">]</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:])</span>

<span class="n">wine</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">cols</span><span class="p">)</span>
<span class="n">wine</span><span class="p">[</span><span class="s1">&#39;density&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                            <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;squared_error&#39;</span><span class="p">,</span>
                            <span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                            <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">min_weight_fraction_leaf</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                            <span class="n">max_features</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
                            <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                            <span class="n">bootstrap</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">oob_score</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                            <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">ccp_alpha</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                            <span class="n">max_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">ax_</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">ax_</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Train, R2: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">))))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Actual&#39;</span><span class="p">)</span>
<span class="n">ax_</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Actual&#39;</span><span class="p">)</span>
<span class="n">ax_</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Test, R2: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))))</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>Text(0.5, 1.0, &#39;Test, R2: 0.973&#39;)
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_100_1.png" /></p>
<p>Compare these results with our <a href="https://github.com/wesleybeckner/data_science_foundations/blob/fdf84755a7ed6ed54d3f036a7fc2d9dafa79afd9/notebooks/solutions/SOLN_L3_Feature_Engineering.ipynb">linear model</a> from Lab 3.</p>
<p>Recall that we can quickly grab the names of the paramters in our sklearn model:</p>
<div class="codehilite"><pre><span></span><code><span class="n">RandomForestRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>{&#39;bootstrap&#39;: True,
 &#39;ccp_alpha&#39;: 0.0,
 &#39;criterion&#39;: &#39;squared_error&#39;,
 &#39;max_depth&#39;: None,
 &#39;max_features&#39;: &#39;auto&#39;,
 &#39;max_leaf_nodes&#39;: None,
 &#39;max_samples&#39;: None,
 &#39;min_impurity_decrease&#39;: 0.0,
 &#39;min_samples_leaf&#39;: 1,
 &#39;min_samples_split&#39;: 2,
 &#39;min_weight_fraction_leaf&#39;: 0.0,
 &#39;n_estimators&#39;: 100,
 &#39;n_jobs&#39;: None,
 &#39;oob_score&#39;: False,
 &#39;random_state&#39;: None,
 &#39;verbose&#39;: 0,
 &#39;warm_start&#39;: False}
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># Cell for Exercise 2</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&lt;matplotlib.legend.Legend at 0x7f1fe5063f40&gt;
</code></pre></div>

<p><img alt="png" src="../S6_Bagging_files/S6_Bagging_104_1.png" /></p>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../S5_Unsupervised_Learning/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Unsupervised Learning" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Unsupervised Learning
            </div>
          </div>
        </a>
      
      
        
        <a href="../S7_Boosting/" class="md-footer__link md-footer__link--next" aria-label="Next: Boosting" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Boosting
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2022 Wesley Beckner
    </div>
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../assets/javascripts/workers/search.361d90f1.min.js"}</script>
    
    
      <script src="../assets/javascripts/bundle.289a2a4b.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  </body>
</html>