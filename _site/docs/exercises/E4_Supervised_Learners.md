<a href="https://colab.research.google.com/github/wesleybeckner/data_science_foundations/blob/main/notebooks/exercises/E4_Supervised_Learners.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

# Data Science Foundations, Lab 4: Practice with Supervised Learners

**Instructor**: Wesley Beckner

**Contact**: wesleybeckner@gmail.com

---

<br>

In this lab we will continue to practice creation of pipelines, feature engineering, and applying learning algorithms.

Now that we have covered supervised learning methods, and we've covered Grid Search, we will use these tools to do a sophisticated, search of hyperparameter optimization.

<br>

---




# L3 Q1: 

Create train and test datasets for wine quality

Create new train/test datasets that are normalized (but have the same indices as the original train/test sets for comparison)


```python
# Code Cell for L1 Q1
```

# L3 Q2:

Evaluate the performance of a Random Forest on classifying wine quality



```python
# Code Cell for L1 Q2
```

# L3 Q3:

Do a grid search to optimize your Random Forest model, use whatever hyperparameters you would like




```python
# Code Cell for L1 Q3
```
